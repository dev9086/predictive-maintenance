# ğŸ­ Predictive Maintenance System - Status Report
**Date:** December 21, 2025

## âœ… System Status: ALL WORKING

### 1. Database Status âœ…
- **Connection:** Working
- **Sensor Readings:** 10,000 records
- **Model Predictions:** 1,050 records
- **Tables:** All created successfully
- **Connection Type:** PostgreSQL via psycopg2

### 2. Streamlit Dashboard âœ…
- **Status:** Running on http://localhost:8501
- **Port:** 8501
- **Auto-reload:** Enabled

#### New Features Added:
âœ¨ **3 Modes Available:**

1. **Machine Dashboard** (Original)
   - Select machine from database
   - View latest sensor readings
   - See real-time predictions
   - View prediction history with charts

2. **Manual Prediction** (NEW)
   - Enter sensor values manually
   - Get instant predictions
   - See detailed risk assessment
   - View recommendations
   - Perfect for testing scenarios

3. **Batch Predictions** (NEW)
   - Upload CSV file with multiple rows
   - Or manually enter multiple rows
   - Get predictions for all rows at once
   - Download results as CSV
   - View summary statistics
   - Progress bar for large batches

### 3. FastAPI Server âœ…
- **Status:** Running on http://127.0.0.1:8000
- **Port:** 8000
- **Auto-reload:** Enabled
- **API Docs:** http://127.0.0.1:8000/docs
- **Models:** Loaded at startup

#### Available Endpoints:
- `POST /predict` - Single prediction
- `GET /health` - Health check
- API documentation with Swagger UI

### 4. ML Models âœ…
- **Location:** `models/` directory
- **Files:**
  - `classifier.pkl` - Failure prediction
  - `regressor.pkl` - RUL estimation
  - `anomaly_detector.pkl` - Anomaly detection
  - `scaler.joblib` - Feature scaling
  - `feature_columns.txt` - Feature names (90 features)

- **Inference Engine:** Hybrid approach
  - Primary: ML models (trained)
  - Fallback: Physics-based simulator
  - Feature engineering: 5 raw â†’ 90 engineered features

### 5. Web Scraper âœ…
- **Status:** Available in `src/web_scraper.py`
- **Purpose:** Scrape manufacturer specs and reliability data
- **Features:**
  - Static website scraping (BeautifulSoup)
  - Dynamic website scraping (Selenium)
  - MTBF data extraction
  - Parts lifecycle information
  - Industry benchmarks

**Usage:**
```python
from web_scraper import MaintenanceDataScraper
scraper = MaintenanceDataScraper()
scraper.scrape_manufacturer_specs_static(url, machine_id)
```

### 6. Data Pipeline âœ…
**Flow:**
1. Raw sensor data â†’ `data/raw/ai4i2020.csv`
2. ETL process â†’ `src/etl.py`
3. Database storage â†’ PostgreSQL
4. Model inference â†’ `src/model_inference.py`
5. Predictions â†’ Database
6. Visualization â†’ Streamlit Dashboard

## ğŸ¯ How to Use

### Access Streamlit Dashboard:
1. Open browser: http://localhost:8501
2. Select mode from sidebar:
   - **Machine Dashboard:** Monitor existing machines
   - **Manual Prediction:** Test with custom values
   - **Batch Predictions:** Analyze multiple scenarios

### Manual Prediction Example:
1. Select "Manual Prediction" mode
2. Enter values:
   - Air Temperature: 25.0Â°C
   - Process Temperature: 35.0Â°C
   - Rotational Speed: 1500 RPM
   - Torque: 40.0 Nm
   - Tool Wear: 100 minutes
3. Click "ğŸ”® Predict"
4. View results:
   - Failure probability
   - Remaining useful life
   - Anomaly status
   - Risk level
   - Recommendations

### Batch Prediction Example:
1. Select "Batch Predictions" mode
2. Choose tab:
   - **Upload CSV:** Upload file with columns
   - **Manual Entry:** Enter multiple rows
3. CSV format:
```csv
air_temperature,process_temperature,rotational_speed,torque,tool_wear
25.0,35.0,1500,40.0,100
30.0,42.0,1600,45.0,150
28.5,38.5,1550,42.5,120
```
4. Click "ğŸ”® Run Batch Predictions"
5. Download results as CSV

### API Usage:
```bash
# Single prediction
curl -X POST "http://127.0.0.1:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "machine_id": 1,
    "features": {
      "air_temperature": 25.0,
      "process_temperature": 35.0,
      "rotational_speed": 1500,
      "torque": 40.0,
      "tool_wear": 100
    }
  }'
```

## ğŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Data   â”‚
â”‚ (CSV/DB)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ETL/Data   â”‚
â”‚  Pipeline   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL  â”‚â—„â”€â”€â”€â”€â–ºâ”‚  Web Scraper â”‚
â”‚  Database   â”‚      â”‚  (External)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       v                      v                  v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚      â”‚  Streamlit  â”‚    â”‚  ML Models  â”‚
â”‚  (Port 8000)â”‚      â”‚ (Port 8501) â”‚    â”‚   Engine    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                      â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      v
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   User      â”‚
              â”‚ Interface   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Maintenance

### Stop Services:
```powershell
# Stop Streamlit (Ctrl+C in terminal)
# Stop FastAPI (Ctrl+C in terminal)
```

### Restart Services:
```powershell
# Terminal 1: FastAPI
.\.venv\Scripts\Activate.ps1
uvicorn src.fastapi_server:app --host 127.0.0.1 --port 8000 --reload

# Terminal 2: Streamlit
.\.venv\Scripts\Activate.ps1
streamlit run src/streamlit_dashboard.py --server.port 8501
```

### Retrain Models:
```powershell
python src/simple_model_training.py
```

## ğŸ“ Notes

1. **Web Scraper:** Available but requires target URLs to be configured
2. **Models:** Currently using 90-feature models with feature engineering
3. **Fallback:** Physics-based predictor available if ML models fail
4. **Database:** 10,000 sensor readings ready for training/testing

## âœ¨ Recent Enhancements

- âœ… Added Manual Prediction mode for custom input
- âœ… Added Batch Prediction mode (CSV upload + manual entry)
- âœ… Progress bars for batch processing
- âœ… CSV download for batch results
- âœ… Enhanced risk assessment visualization
- âœ… Summary statistics for batch predictions
- âœ… Interactive data editor for manual batch entry

---

**System Ready for Production! ğŸš€**
